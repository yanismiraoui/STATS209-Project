{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects:  1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['timeseires', 'label', 'corr', 'pcorr', 'site', 'id'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(f\"./data/abide.npy\",allow_pickle=True).item()\n",
    "print(\"Number of subjects: \", len(data['label']))\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectome (X) shape: (1009, 116, 116)\n"
     ]
    }
   ],
   "source": [
    "conn = data[\"corr\"]\n",
    "print(f\"Connectome (X) shape: {conn.shape}\") # n_ROIs, n_ROIs, n_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASD scores (y) shape: (1009,)\n"
     ]
    }
   ],
   "source": [
    "scores = data[\"label\"]\n",
    "print(f\"ASD scores (y) shape: {scores.shape}\") # n_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject IDs shape: 1009\n"
     ]
    }
   ],
   "source": [
    "subject_ids = [int(i) for i in data[\"id\"]]\n",
    "print(f\"Subject IDs shape: {len(subject_ids)}\") # n_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(13456, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, latent_dim)  # Compressed representation\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 13456),\n",
    "            nn.Sigmoid()  # Output values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (807, 116, 116)\n",
      "X_test shape: (202, 116, 116)\n",
      "y_train shape: (807,)\n",
      "y_test shape: (202,)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(conn, scores, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 116, 116)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "# change the length of X_train to match batch_size\n",
    "X_train = X_train[:len(X_train) - (len(X_train) % batch_size)]\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "train_loader = DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0336, Test loss: 0.0365\n",
      "Epoch [2/10], Loss: 0.0485, Test loss: 0.0367\n",
      "Epoch [3/10], Loss: 0.0329, Test loss: 0.0359\n",
      "Epoch [4/10], Loss: 0.0374, Test loss: 0.0346\n",
      "Epoch [5/10], Loss: 0.0291, Test loss: 0.0337\n",
      "Epoch [6/10], Loss: 0.0312, Test loss: 0.0341\n",
      "Epoch [7/10], Loss: 0.0471, Test loss: 0.0336\n",
      "Epoch [8/10], Loss: 0.0326, Test loss: 0.0337\n",
      "Epoch [9/10], Loss: 0.0330, Test loss: 0.0339\n",
      "Epoch [10/10], Loss: 0.0347, Test loss: 0.0337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for d in train_loader:\n",
    "        matrix = d.float()\n",
    "        # reshape\n",
    "        matrix = matrix.view(matrix.size(0), -1)\n",
    "        output = model(matrix)\n",
    "        loss = criterion(output, matrix)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Evaluate on test set\n",
    "    test_matrix = torch.tensor(X_test).float()\n",
    "    test_matrix = test_matrix.view(test_matrix.size(0), -1)\n",
    "    test_output = model(test_matrix)\n",
    "    test_loss = criterion(test_output, test_matrix)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Test loss: {test_loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial X shape: (1009, 116, 116)\n",
      "Adapted X shape: (1009, 116, 116)\n",
      "Epoch [1/10], Loss: 0.1061\n",
      "Epoch [2/10], Loss: 0.0218\n",
      "Epoch [3/10], Loss: 0.0385\n",
      "Epoch [4/10], Loss: 0.0457\n",
      "Epoch [5/10], Loss: 0.0311\n",
      "Epoch [6/10], Loss: 0.0284\n",
      "Epoch [7/10], Loss: 0.0404\n",
      "Epoch [8/10], Loss: 0.0262\n",
      "Epoch [9/10], Loss: 0.0274\n",
      "Epoch [10/10], Loss: 0.0336\n"
     ]
    }
   ],
   "source": [
    "# Train on all data as it is an unsupervised task\n",
    "\n",
    "# Initiliaze model\n",
    "model = Autoencoder().float()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Determine batch size and adapt dataset\n",
    "batch_size = 1\n",
    "# change the length of X_train to match batch_size\n",
    "conn = conn[:len(conn) - (len(conn) % batch_size)]\n",
    "subject_ids = subject_ids[:len(subject_ids) - (len(subject_ids) % batch_size)]\n",
    "print(f\"Initial X shape: {conn.shape}\")\n",
    "print(f\"Adapted X shape: {conn.shape}\")\n",
    "X_loader = DataLoader(conn, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for d in X_loader:\n",
    "        matrix = d.float()\n",
    "        # reshape\n",
    "        matrix = matrix.view(matrix.size(0), -1)\n",
    "        output = model(matrix)\n",
    "        loss = criterion(output, matrix)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0341\n"
     ]
    }
   ],
   "source": [
    "# Get predictions for all data (train and test combined)\n",
    "all_data = torch.tensor(conn).float()\n",
    "all_data = all_data.view(all_data.size(0), -1)\n",
    "all_output = model(all_data)\n",
    "all_loss = criterion(all_output, all_data)\n",
    "print(f'Loss: {all_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressed representation shape: (1009, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get the compressed representation\n",
    "compressed = model.encoder(all_data)\n",
    "compressed = compressed.detach().numpy()\n",
    "print(f\"Compressed representation shape: {compressed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_notes_rater_1</th>\n",
       "      <th>qc_anat_rater_2</th>\n",
       "      <th>qc_anat_notes_rater_2</th>\n",
       "      <th>qc_func_rater_2</th>\n",
       "      <th>qc_func_notes_rater_2</th>\n",
       "      <th>qc_anat_rater_3</th>\n",
       "      <th>qc_anat_notes_rater_3</th>\n",
       "      <th>qc_func_rater_3</th>\n",
       "      <th>qc_func_notes_rater_3</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.77</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fail</td>\n",
       "      <td>ERROR #24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.45</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.09</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal-cerebellum</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>maybe</td>\n",
       "      <td>ic-parietal slight</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP  DSM_IV_TR  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1          1   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1          1   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1          1   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1          1   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1          1   \n",
       "\n",
       "   AGE_AT_SCAN  SEX  ... qc_notes_rater_1  qc_anat_rater_2  \\\n",
       "0        16.77    1  ...              NaN               OK   \n",
       "1        24.45    1  ...              NaN               OK   \n",
       "2        19.09    1  ...              NaN               OK   \n",
       "3        13.73    2  ...              NaN               OK   \n",
       "4        13.37    1  ...              NaN               OK   \n",
       "\n",
       "   qc_anat_notes_rater_2  qc_func_rater_2   qc_func_notes_rater_2  \\\n",
       "0                    NaN             fail  ic-parietal-cerebellum   \n",
       "1                    NaN               OK                     NaN   \n",
       "2                    NaN               OK                     NaN   \n",
       "3                    NaN            maybe  ic-parietal-cerebellum   \n",
       "4                    NaN            maybe      ic-parietal slight   \n",
       "\n",
       "  qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3  \\\n",
       "0              OK                   NaN            fail   \n",
       "1              OK                   NaN              OK   \n",
       "2              OK                   NaN              OK   \n",
       "3              OK                   NaN              OK   \n",
       "4              OK                   NaN              OK   \n",
       "\n",
       "   qc_func_notes_rater_3  SUB_IN_SMP  \n",
       "0              ERROR #24           1  \n",
       "1                    NaN           1  \n",
       "2                    NaN           1  \n",
       "3                    NaN           0  \n",
       "4                    NaN           1  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load original csv file\n",
    "PATH_CSV = \"./data/ABIDE_tab.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH_CSV, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 1009\n",
      "Number of compressed values: 1009\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to hold sub_id and corresponding compressed values\n",
    "print(f\"Number of subjects: {len(subject_ids)}\")\n",
    "print(f\"Number of compressed values: {len(compressed)}\")\n",
    "compressed_dict = {sub_id: compressed[i] for i, sub_id in enumerate(subject_ids)}\n",
    "\n",
    "# Function to return the compressed value for a given sub_id\n",
    "def get_compressed_value(row, subject_ids, compressed):\n",
    "    if row['SUB_ID'] in subject_ids:\n",
    "        index = subject_ids.index(row['SUB_ID'])\n",
    "        return compressed[index]\n",
    "    return np.nan  # or return the default value you want in case of no match\n",
    "\n",
    "# Apply this function to each row in the DataFrame\n",
    "df['compressed'] = df.apply(get_compressed_value, axis=1, args=(subject_ids, compressed))\n",
    "\n",
    "# Save df to csv\n",
    "df.to_csv(\"./data/ABIDE_tab_compressed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 1112\n",
      "Number of compressed values: 1009\n",
      "Number of subjects with no MRI: 103\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of subjects: {len(df)}\")\n",
    "print(f\"Number of compressed values: {len(compressed)}\")\n",
    "print(f\"Number of subjects with no MRI: {df['compressed'].isna().sum()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce the same pipeline for different size of latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent size: 2\n",
      "Epoch [1/10], Loss: 0.0285\n",
      "Epoch [2/10], Loss: 0.0351\n",
      "Epoch [3/10], Loss: 0.0491\n",
      "Epoch [4/10], Loss: 0.0356\n",
      "Epoch [5/10], Loss: 0.0309\n",
      "Epoch [6/10], Loss: 0.0396\n",
      "Epoch [7/10], Loss: 0.0276\n",
      "Epoch [8/10], Loss: 0.0386\n",
      "Epoch [9/10], Loss: 0.0307\n",
      "Epoch [10/10], Loss: 0.0393\n",
      "Loss: 0.0332\n",
      "Compressed representation shape: (1009, 2)\n",
      "Latent size: 3\n",
      "Epoch [1/10], Loss: 0.0242\n",
      "Epoch [2/10], Loss: 0.0266\n",
      "Epoch [3/10], Loss: 0.0308\n",
      "Epoch [4/10], Loss: 0.0254\n",
      "Epoch [5/10], Loss: 0.0359\n",
      "Epoch [6/10], Loss: 0.0276\n",
      "Epoch [7/10], Loss: 0.0322\n",
      "Epoch [8/10], Loss: 0.0357\n",
      "Epoch [9/10], Loss: 0.0478\n",
      "Epoch [10/10], Loss: 0.0263\n",
      "Loss: 0.0325\n",
      "Compressed representation shape: (1009, 3)\n",
      "Latent size: 4\n",
      "Epoch [1/10], Loss: 0.0717\n",
      "Epoch [2/10], Loss: 0.0216\n",
      "Epoch [3/10], Loss: 0.0407\n",
      "Epoch [4/10], Loss: 0.0274\n",
      "Epoch [5/10], Loss: 0.0439\n",
      "Epoch [6/10], Loss: 0.0371\n",
      "Epoch [7/10], Loss: 0.0345\n",
      "Epoch [8/10], Loss: 0.0293\n",
      "Epoch [9/10], Loss: 0.0262\n",
      "Epoch [10/10], Loss: 0.0308\n",
      "Loss: 0.0347\n",
      "Compressed representation shape: (1009, 4)\n",
      "Latent size: 6\n",
      "Epoch [1/10], Loss: 0.0325\n",
      "Epoch [2/10], Loss: 0.0273\n",
      "Epoch [3/10], Loss: 0.0320\n",
      "Epoch [4/10], Loss: 0.0547\n",
      "Epoch [5/10], Loss: 0.0338\n",
      "Epoch [6/10], Loss: 0.0297\n",
      "Epoch [7/10], Loss: 0.0349\n",
      "Epoch [8/10], Loss: 0.0372\n",
      "Epoch [9/10], Loss: 0.0276\n",
      "Epoch [10/10], Loss: 0.0326\n",
      "Loss: 0.0336\n",
      "Compressed representation shape: (1009, 6)\n",
      "Latent size: 8\n",
      "Epoch [1/10], Loss: 0.0349\n",
      "Epoch [2/10], Loss: 0.0300\n",
      "Epoch [3/10], Loss: 0.0363\n",
      "Epoch [4/10], Loss: 0.0283\n",
      "Epoch [5/10], Loss: 0.0186\n",
      "Epoch [6/10], Loss: 0.0527\n",
      "Epoch [7/10], Loss: 0.0310\n",
      "Epoch [8/10], Loss: 0.0300\n",
      "Epoch [9/10], Loss: 0.0282\n",
      "Epoch [10/10], Loss: 0.0327\n",
      "Loss: 0.0321\n",
      "Compressed representation shape: (1009, 8)\n",
      "Latent size: 10\n",
      "Epoch [1/10], Loss: 0.0447\n",
      "Epoch [2/10], Loss: 0.0358\n",
      "Epoch [3/10], Loss: 0.0306\n",
      "Epoch [4/10], Loss: 0.0332\n",
      "Epoch [5/10], Loss: 0.0389\n",
      "Epoch [6/10], Loss: 0.0431\n",
      "Epoch [7/10], Loss: 0.0314\n",
      "Epoch [8/10], Loss: 0.0369\n",
      "Epoch [9/10], Loss: 0.0328\n",
      "Epoch [10/10], Loss: 0.0328\n",
      "Loss: 0.0327\n",
      "Compressed representation shape: (1009, 10)\n"
     ]
    }
   ],
   "source": [
    "latent_sizes = [2, 3, 4, 6, 8, 10]\n",
    "for latent_size in latent_sizes:\n",
    "    print(f\"Latent size: {latent_size}\")\n",
    "    # Initiliaze model\n",
    "    model = Autoencoder(latent_dim=latent_size).float()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    X_loader = DataLoader(conn, batch_size=1, shuffle=True)\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        for d in X_loader:\n",
    "            matrix = d.float()\n",
    "            matrix = matrix.view(matrix.size(0), -1)\n",
    "            output = model(matrix)\n",
    "            loss = criterion(output, matrix)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Get predictions for all data (train and test combined)\n",
    "    all_data = torch.tensor(conn).float()\n",
    "    all_data = all_data.view(all_data.size(0), -1)\n",
    "    all_output = model(all_data)\n",
    "    all_loss = criterion(all_output, all_data)\n",
    "    print(f'Loss: {all_loss.item():.4f}')\n",
    "\n",
    "\n",
    "    # Get the compressed representation\n",
    "    compressed = model.encoder(all_data)\n",
    "    compressed = compressed.detach().numpy()\n",
    "    print(f\"Compressed representation shape: {compressed.shape}\")\n",
    "\n",
    "    # Create a dictionary to hold sub_id and corresponding compressed values\n",
    "    compressed_dict = {sub_id: list(compressed[i]) for i, sub_id in enumerate(subject_ids)}\n",
    "\n",
    "    # Apply this function to each row in the DataFrame\n",
    "    df[f\"compressed_{latent_size}\"] = df.apply(get_compressed_value, axis=1, args=(subject_ids, compressed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[f\"compressed_{latent_size}\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent size: 2, component: 1\n",
      "Latent size: 2, component: 2\n",
      "Latent size: 3, component: 1\n",
      "Latent size: 3, component: 2\n",
      "Latent size: 3, component: 3\n",
      "Latent size: 4, component: 1\n",
      "Latent size: 4, component: 2\n",
      "Latent size: 4, component: 3\n",
      "Latent size: 4, component: 4\n",
      "Latent size: 6, component: 1\n",
      "Latent size: 6, component: 2\n",
      "Latent size: 6, component: 3\n",
      "Latent size: 6, component: 4\n",
      "Latent size: 6, component: 5\n",
      "Latent size: 6, component: 6\n",
      "Latent size: 8, component: 1\n",
      "Latent size: 8, component: 2\n",
      "Latent size: 8, component: 3\n",
      "Latent size: 8, component: 4\n",
      "Latent size: 8, component: 5\n",
      "Latent size: 8, component: 6\n",
      "Latent size: 8, component: 7\n",
      "Latent size: 8, component: 8\n",
      "Latent size: 10, component: 1\n",
      "Latent size: 10, component: 2\n",
      "Latent size: 10, component: 3\n",
      "Latent size: 10, component: 4\n",
      "Latent size: 10, component: 5\n",
      "Latent size: 10, component: 6\n",
      "Latent size: 10, component: 7\n",
      "Latent size: 10, component: 8\n",
      "Latent size: 10, component: 9\n",
      "Latent size: 10, component: 10\n"
     ]
    }
   ],
   "source": [
    "# Decompose each element of compressed_2, compressed_3, compressed_4, compressed_6, compressed_8, compressed_10\n",
    "# into separate columns named for example compressed_2_1, compressed_2_2, compressed_2_3 for 2\n",
    "# and compressed_3_1, compressed_3_2, compressed_3_3 for 3\n",
    "\n",
    "for latent_size in latent_sizes:\n",
    "    for i in range(latent_size):\n",
    "        print(f\"Latent size: {latent_size}, component: {i+1}\")\n",
    "        # if nan skip \n",
    "        df[f\"compressed_{latent_size}_{i+1}\"] = df[f\"compressed_{latent_size}\"].apply(lambda x: x[i] if not np.isnan(x).any() else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>...</th>\n",
       "      <th>compressed_10_1</th>\n",
       "      <th>compressed_10_2</th>\n",
       "      <th>compressed_10_3</th>\n",
       "      <th>compressed_10_4</th>\n",
       "      <th>compressed_10_5</th>\n",
       "      <th>compressed_10_6</th>\n",
       "      <th>compressed_10_7</th>\n",
       "      <th>compressed_10_8</th>\n",
       "      <th>compressed_10_9</th>\n",
       "      <th>compressed_10_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.77</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.45</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909656</td>\n",
       "      <td>0.481762</td>\n",
       "      <td>0.884295</td>\n",
       "      <td>-0.988569</td>\n",
       "      <td>-0.472216</td>\n",
       "      <td>1.179701</td>\n",
       "      <td>-4.691446</td>\n",
       "      <td>1.285244</td>\n",
       "      <td>0.304127</td>\n",
       "      <td>-1.236132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.09</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490374</td>\n",
       "      <td>0.429602</td>\n",
       "      <td>0.585015</td>\n",
       "      <td>-0.724735</td>\n",
       "      <td>-0.285081</td>\n",
       "      <td>0.603682</td>\n",
       "      <td>-3.106297</td>\n",
       "      <td>1.142545</td>\n",
       "      <td>0.212014</td>\n",
       "      <td>-0.834060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246707</td>\n",
       "      <td>0.242712</td>\n",
       "      <td>-0.032542</td>\n",
       "      <td>-2.295534</td>\n",
       "      <td>0.225910</td>\n",
       "      <td>0.307312</td>\n",
       "      <td>-2.314953</td>\n",
       "      <td>3.458993</td>\n",
       "      <td>-0.867373</td>\n",
       "      <td>-0.172947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184293</td>\n",
       "      <td>0.258914</td>\n",
       "      <td>0.252984</td>\n",
       "      <td>-0.554248</td>\n",
       "      <td>-0.206663</td>\n",
       "      <td>0.108282</td>\n",
       "      <td>-1.661348</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.053556</td>\n",
       "      <td>-0.439587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1108</td>\n",
       "      <td>51583</td>\n",
       "      <td>1108</td>\n",
       "      <td>51583</td>\n",
       "      <td>SBL</td>\n",
       "      <td>SBL_0051583</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980515</td>\n",
       "      <td>0.530008</td>\n",
       "      <td>0.981649</td>\n",
       "      <td>-1.146998</td>\n",
       "      <td>-0.465993</td>\n",
       "      <td>1.348539</td>\n",
       "      <td>-5.197294</td>\n",
       "      <td>1.499649</td>\n",
       "      <td>0.304935</td>\n",
       "      <td>-1.349291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>1109</td>\n",
       "      <td>51584</td>\n",
       "      <td>1109</td>\n",
       "      <td>51584</td>\n",
       "      <td>SBL</td>\n",
       "      <td>SBL_0051584</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>49.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.590604</td>\n",
       "      <td>0.400444</td>\n",
       "      <td>1.424278</td>\n",
       "      <td>-1.344318</td>\n",
       "      <td>-0.756654</td>\n",
       "      <td>2.030421</td>\n",
       "      <td>-7.098702</td>\n",
       "      <td>1.600666</td>\n",
       "      <td>0.510455</td>\n",
       "      <td>-1.873910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1110</td>\n",
       "      <td>51585</td>\n",
       "      <td>1110</td>\n",
       "      <td>51585</td>\n",
       "      <td>SBL</td>\n",
       "      <td>SBL_0051585</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702105</td>\n",
       "      <td>-0.133351</td>\n",
       "      <td>0.431572</td>\n",
       "      <td>0.204039</td>\n",
       "      <td>-0.664004</td>\n",
       "      <td>0.166147</td>\n",
       "      <td>-1.663145</td>\n",
       "      <td>-0.237840</td>\n",
       "      <td>0.470579</td>\n",
       "      <td>-0.636842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1111</td>\n",
       "      <td>51606</td>\n",
       "      <td>1111</td>\n",
       "      <td>51606</td>\n",
       "      <td>MAX_MUN</td>\n",
       "      <td>MaxMun_a_0051606</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29.00</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087650</td>\n",
       "      <td>0.148457</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>-0.129910</td>\n",
       "      <td>-0.277422</td>\n",
       "      <td>-0.260822</td>\n",
       "      <td>-0.504564</td>\n",
       "      <td>0.294545</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>-0.194899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>1112</td>\n",
       "      <td>51607</td>\n",
       "      <td>1112</td>\n",
       "      <td>51607</td>\n",
       "      <td>MAX_MUN</td>\n",
       "      <td>MaxMun_a_0051607</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247730</td>\n",
       "      <td>0.227721</td>\n",
       "      <td>-0.107436</td>\n",
       "      <td>-1.996096</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.156443</td>\n",
       "      <td>-1.829311</td>\n",
       "      <td>2.967384</td>\n",
       "      <td>-0.774861</td>\n",
       "      <td>-0.102152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1112 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  SUB_ID     X  subject  SITE_ID           FILE_ID  DX_GROUP  \\\n",
       "0              1   50002     1    50002     PITT       no_filename         1   \n",
       "1              2   50003     2    50003     PITT      Pitt_0050003         1   \n",
       "2              3   50004     3    50004     PITT      Pitt_0050004         1   \n",
       "3              4   50005     4    50005     PITT      Pitt_0050005         1   \n",
       "4              5   50006     5    50006     PITT      Pitt_0050006         1   \n",
       "...          ...     ...   ...      ...      ...               ...       ...   \n",
       "1107        1108   51583  1108    51583      SBL       SBL_0051583         1   \n",
       "1108        1109   51584  1109    51584      SBL       SBL_0051584         1   \n",
       "1109        1110   51585  1110    51585      SBL       SBL_0051585         1   \n",
       "1110        1111   51606  1111    51606  MAX_MUN  MaxMun_a_0051606         1   \n",
       "1111        1112   51607  1112    51607  MAX_MUN  MaxMun_a_0051607         1   \n",
       "\n",
       "      DSM_IV_TR  AGE_AT_SCAN  SEX  ... compressed_10_1  compressed_10_2  \\\n",
       "0             1        16.77    1  ...             NaN              NaN   \n",
       "1             1        24.45    1  ...        0.909656         0.481762   \n",
       "2             1        19.09    1  ...        0.490374         0.429602   \n",
       "3             1        13.73    2  ...       -0.246707         0.242712   \n",
       "4             1        13.37    1  ...        0.184293         0.258914   \n",
       "...         ...          ...  ...  ...             ...              ...   \n",
       "1107          2        35.00    1  ...        0.980515         0.530008   \n",
       "1108          2        49.00    1  ...        1.590604         0.400444   \n",
       "1109          1        27.00    1  ...        0.702105        -0.133351   \n",
       "1110          2        29.00    2  ...        0.087650         0.148457   \n",
       "1111          2        26.00    1  ...       -0.247730         0.227721   \n",
       "\n",
       "      compressed_10_3  compressed_10_4  compressed_10_5 compressed_10_6  \\\n",
       "0                 NaN              NaN              NaN             NaN   \n",
       "1            0.884295        -0.988569        -0.472216        1.179701   \n",
       "2            0.585015        -0.724735        -0.285081        0.603682   \n",
       "3           -0.032542        -2.295534         0.225910        0.307312   \n",
       "4            0.252984        -0.554248        -0.206663        0.108282   \n",
       "...               ...              ...              ...             ...   \n",
       "1107         0.981649        -1.146998        -0.465993        1.348539   \n",
       "1108         1.424278        -1.344318        -0.756654        2.030421   \n",
       "1109         0.431572         0.204039        -0.664004        0.166147   \n",
       "1110         0.017554        -0.129910        -0.277422       -0.260822   \n",
       "1111        -0.107436        -1.996096         0.164368        0.156443   \n",
       "\n",
       "     compressed_10_7 compressed_10_8  compressed_10_9  compressed_10_10  \n",
       "0                NaN             NaN              NaN               NaN  \n",
       "1          -4.691446        1.285244         0.304127         -1.236132  \n",
       "2          -3.106297        1.142545         0.212014         -0.834060  \n",
       "3          -2.314953        3.458993        -0.867373         -0.172947  \n",
       "4          -1.661348        0.986131         0.053556         -0.439587  \n",
       "...              ...             ...              ...               ...  \n",
       "1107       -5.197294        1.499649         0.304935         -1.349291  \n",
       "1108       -7.098702        1.600666         0.510455         -1.873910  \n",
       "1109       -1.663145       -0.237840         0.470579         -0.636842  \n",
       "1110       -0.504564        0.294545         0.094053         -0.194899  \n",
       "1111       -1.829311        2.967384        -0.774861         -0.102152  \n",
       "\n",
       "[1112 rows x 145 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>X</th>\n",
       "      <th>subject</th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>FILE_ID</th>\n",
       "      <th>DX_GROUP</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>SEX</th>\n",
       "      <th>...</th>\n",
       "      <th>qc_func_rater_3</th>\n",
       "      <th>qc_func_notes_rater_3</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "      <th>compressed</th>\n",
       "      <th>compressed_2</th>\n",
       "      <th>compressed_3</th>\n",
       "      <th>compressed_4</th>\n",
       "      <th>compressed_6</th>\n",
       "      <th>compressed_8</th>\n",
       "      <th>compressed_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>50002</td>\n",
       "      <td>PITT</td>\n",
       "      <td>no_filename</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.77</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>fail</td>\n",
       "      <td>ERROR #24</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>2</td>\n",
       "      <td>50003</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.45</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[5.5358014, -1.9740214, 3.8024192]</td>\n",
       "      <td>[-4.1329317, 1.915973]</td>\n",
       "      <td>[2.3084972, -2.857194, -4.6895466]</td>\n",
       "      <td>[-0.33113953, 0.81164557, 0.37227333, 0.96400756]</td>\n",
       "      <td>[-2.2387748, -3.5640666, 0.09702098, -2.160834...</td>\n",
       "      <td>[-2.2480175, 1.6303325, 0.5056043, -0.6117266,...</td>\n",
       "      <td>[0.9096564, 0.48176152, 0.884295, -0.9885688, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>3</td>\n",
       "      <td>50004</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.09</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[6.946011, -3.0977376, 0.5026052]</td>\n",
       "      <td>[-2.3123832, 1.797447]</td>\n",
       "      <td>[1.9793308, -1.4719096, -2.9629197]</td>\n",
       "      <td>[-0.26281962, 3.867676, 1.8729587, 5.129569]</td>\n",
       "      <td>[-4.1193504, -1.12287, -1.0050129, -2.8992608,...</td>\n",
       "      <td>[-1.5968913, 0.7262498, 0.13404477, -0.2059115...</td>\n",
       "      <td>[0.49037445, 0.4296016, 0.5850151, -0.7247355,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>4</td>\n",
       "      <td>50005</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.5172627, -2.2816546, -3.9345512]</td>\n",
       "      <td>[-0.65785336, -0.8069845]</td>\n",
       "      <td>[4.2407064, 0.033206224, -3.1740694]</td>\n",
       "      <td>[2.7871912, -2.1375813, 0.7781836, 2.761505]</td>\n",
       "      <td>[-3.411883, 3.6637545, 2.3138394, 1.0991508, -...</td>\n",
       "      <td>[-1.9579207, -2.4649396, -0.09315338, 0.743613...</td>\n",
       "      <td>[-0.24670707, 0.24271171, -0.03254228, -2.2955...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>5</td>\n",
       "      <td>50006</td>\n",
       "      <td>PITT</td>\n",
       "      <td>Pitt_0050006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.37</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>OK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[15.962503, -7.3864527, -3.2940526]</td>\n",
       "      <td>[0.6298959, 3.0843263]</td>\n",
       "      <td>[1.3287704, -0.59391, -1.7520998]</td>\n",
       "      <td>[1.8689116, 10.683505, 6.043604, 16.954182]</td>\n",
       "      <td>[-10.793749, 0.7768371, -1.8503393, -5.9783297...</td>\n",
       "      <td>[-1.0171833, -0.13308728, -0.34721193, 0.30007...</td>\n",
       "      <td>[0.18429323, 0.258914, 0.25298434, -0.55424833...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP  DSM_IV_TR  \\\n",
       "0           1   50002  1    50002    PITT   no_filename         1          1   \n",
       "1           2   50003  2    50003    PITT  Pitt_0050003         1          1   \n",
       "2           3   50004  3    50004    PITT  Pitt_0050004         1          1   \n",
       "3           4   50005  4    50005    PITT  Pitt_0050005         1          1   \n",
       "4           5   50006  5    50006    PITT  Pitt_0050006         1          1   \n",
       "\n",
       "   AGE_AT_SCAN  SEX  ... qc_func_rater_3  qc_func_notes_rater_3  SUB_IN_SMP  \\\n",
       "0        16.77    1  ...            fail              ERROR #24           1   \n",
       "1        24.45    1  ...              OK                    NaN           1   \n",
       "2        19.09    1  ...              OK                    NaN           1   \n",
       "3        13.73    2  ...              OK                    NaN           0   \n",
       "4        13.37    1  ...              OK                    NaN           1   \n",
       "\n",
       "                            compressed               compressed_2  \\\n",
       "0                                  NaN                        NaN   \n",
       "1   [5.5358014, -1.9740214, 3.8024192]     [-4.1329317, 1.915973]   \n",
       "2    [6.946011, -3.0977376, 0.5026052]     [-2.3123832, 1.797447]   \n",
       "3  [3.5172627, -2.2816546, -3.9345512]  [-0.65785336, -0.8069845]   \n",
       "4  [15.962503, -7.3864527, -3.2940526]     [0.6298959, 3.0843263]   \n",
       "\n",
       "                           compressed_3  \\\n",
       "0                                   NaN   \n",
       "1    [2.3084972, -2.857194, -4.6895466]   \n",
       "2   [1.9793308, -1.4719096, -2.9629197]   \n",
       "3  [4.2407064, 0.033206224, -3.1740694]   \n",
       "4     [1.3287704, -0.59391, -1.7520998]   \n",
       "\n",
       "                                        compressed_4  \\\n",
       "0                                                NaN   \n",
       "1  [-0.33113953, 0.81164557, 0.37227333, 0.96400756]   \n",
       "2       [-0.26281962, 3.867676, 1.8729587, 5.129569]   \n",
       "3       [2.7871912, -2.1375813, 0.7781836, 2.761505]   \n",
       "4        [1.8689116, 10.683505, 6.043604, 16.954182]   \n",
       "\n",
       "                                        compressed_6  \\\n",
       "0                                                NaN   \n",
       "1  [-2.2387748, -3.5640666, 0.09702098, -2.160834...   \n",
       "2  [-4.1193504, -1.12287, -1.0050129, -2.8992608,...   \n",
       "3  [-3.411883, 3.6637545, 2.3138394, 1.0991508, -...   \n",
       "4  [-10.793749, 0.7768371, -1.8503393, -5.9783297...   \n",
       "\n",
       "                                        compressed_8  \\\n",
       "0                                                NaN   \n",
       "1  [-2.2480175, 1.6303325, 0.5056043, -0.6117266,...   \n",
       "2  [-1.5968913, 0.7262498, 0.13404477, -0.2059115...   \n",
       "3  [-1.9579207, -2.4649396, -0.09315338, 0.743613...   \n",
       "4  [-1.0171833, -0.13308728, -0.34721193, 0.30007...   \n",
       "\n",
       "                                       compressed_10  \n",
       "0                                                NaN  \n",
       "1  [0.9096564, 0.48176152, 0.884295, -0.9885688, ...  \n",
       "2  [0.49037445, 0.4296016, 0.5850151, -0.7247355,...  \n",
       "3  [-0.24670707, 0.24271171, -0.03254228, -2.2955...  \n",
       "4  [0.18429323, 0.258914, 0.25298434, -0.55424833...  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to csv\n",
    "df.to_csv(\"./data/ABIDE_tab_compressed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
